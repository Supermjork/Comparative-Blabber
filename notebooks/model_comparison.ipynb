{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10225541,"sourceType":"datasetVersion","datasetId":6321785},{"sourceId":213660655,"sourceType":"kernelVersion"},{"sourceId":214121457,"sourceType":"kernelVersion"},{"sourceId":214130599,"sourceType":"kernelVersion"}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport polars as pl\nfrom collections import defaultdict","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-21T19:36:02.470483Z","iopub.execute_input":"2024-12-21T19:36:02.470785Z","iopub.status.idle":"2024-12-21T19:36:04.157555Z","shell.execute_reply.started":"2024-12-21T19:36:02.470750Z","shell.execute_reply":"2024-12-21T19:36:04.156605Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T19:36:21.645319Z","iopub.execute_input":"2024-12-21T19:36:21.645770Z","iopub.status.idle":"2024-12-21T19:36:21.669544Z","shell.execute_reply.started":"2024-12-21T19:36:21.645732Z","shell.execute_reply":"2024-12-21T19:36:21.668547Z"}},"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"seq2seq_BATCH_SIZE = 64\nseq2seq_EMB_DIM = 128\nseq2seq_HID_DIM = 258\nseq2seq_N_LAYERS = 2\nseq2seq_DROPOUT = 0.5\nseq2seq_LEARNING_RATE = 0.001\nseq2seq_EPOCHS = 10\nseq2seq_FRAC = 0.2\nseq2seq_SEED = 420","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T19:36:24.380979Z","iopub.execute_input":"2024-12-21T19:36:24.381358Z","iopub.status.idle":"2024-12-21T19:36:24.385681Z","shell.execute_reply.started":"2024-12-21T19:36:24.381325Z","shell.execute_reply":"2024-12-21T19:36:24.384703Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"transformer_BATCH_SIZE = 32\ntransformer_EMB_DIM = 128\ntransformer_HID_DIM = 258\ntransformer_N_LAYERS = 2\ntransformer_N_HEADS = 8\ntransformer_FF_DIM = 512\ntransformer_DROPOUT = 0.1\ntransformer_LEARNING_RATE = 0.001\ntransformer_EPOCHS = 10\ntransformer_FRAC = 0.5\ntransformer_SEED = 420","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T19:36:35.086672Z","iopub.execute_input":"2024-12-21T19:36:35.086975Z","iopub.status.idle":"2024-12-21T19:36:35.091296Z","shell.execute_reply.started":"2024-12-21T19:36:35.086951Z","shell.execute_reply":"2024-12-21T19:36:35.090451Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"kaggle_path= \"/kaggle/input/it-en-translation/processed.parquet\"\nloaded_data = pl.read_parquet(kaggle_path)\nprint(\"Data loaded successfully\")\nloaded_data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T19:36:37.477186Z","iopub.execute_input":"2024-12-21T19:36:37.477534Z","iopub.status.idle":"2024-12-21T19:36:37.823419Z","shell.execute_reply.started":"2024-12-21T19:36:37.477508Z","shell.execute_reply":"2024-12-21T19:36:37.822595Z"}},"outputs":[{"name":"stdout","text":"Data loaded successfully\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"shape: (5, 2)\n┌─────────────────────────────────┬─────────────────────────────────┐\n│ it                              ┆ en                              │\n│ ---                             ┆ ---                             │\n│ list[str]                       ┆ list[str]                       │\n╞═════════════════════════════════╪═════════════════════════════════╡\n│ [\"grazie\", \"amico\"]             ┆ [\"thank\", \"buddy\"]              │\n│ [\"di il\"]                       ┆ [\"say\"]                         │\n│ [\"trifosfare\", \"sodio\", … \"sod… ┆ [\"sodium\", \"triphosphate\", … \"… │\n│ [\"invero\", \"avidare\", … \"ricch… ┆ [\"surely\", \"ardent\", … \"wealth… │\n│ [\"allegare\"]                    ┆ [\"annex\"]                       │\n└─────────────────────────────────┴─────────────────────────────────┘","text/html":"<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>it</th><th>en</th></tr><tr><td>list[str]</td><td>list[str]</td></tr></thead><tbody><tr><td>[&quot;grazie&quot;, &quot;amico&quot;]</td><td>[&quot;thank&quot;, &quot;buddy&quot;]</td></tr><tr><td>[&quot;di il&quot;]</td><td>[&quot;say&quot;]</td></tr><tr><td>[&quot;trifosfare&quot;, &quot;sodio&quot;, … &quot;sodio&quot;]</td><td>[&quot;sodium&quot;, &quot;triphosphate&quot;, … &quot;tripolyphosphate&quot;]</td></tr><tr><td>[&quot;invero&quot;, &quot;avidare&quot;, … &quot;ricchezzo&quot;]</td><td>[&quot;surely&quot;, &quot;ardent&quot;, … &quot;wealth&quot;]</td></tr><tr><td>[&quot;allegare&quot;]</td><td>[&quot;annex&quot;]</td></tr></tbody></table></div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"transformer_input_data = loaded_data.sample(fraction = transformer_FRAC, seed = transformer_SEED)\n\ntransformer_input_data.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T19:36:40.215985Z","iopub.execute_input":"2024-12-21T19:36:40.216330Z","iopub.status.idle":"2024-12-21T19:36:40.488640Z","shell.execute_reply.started":"2024-12-21T19:36:40.216300Z","shell.execute_reply":"2024-12-21T19:36:40.487719Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"shape: (9, 3)\n┌────────────┬──────────┬──────────┐\n│ statistic  ┆ it       ┆ en       │\n│ ---        ┆ ---      ┆ ---      │\n│ str        ┆ f64      ┆ f64      │\n╞════════════╪══════════╪══════════╡\n│ count      ┆ 480021.0 ┆ 480021.0 │\n│ null_count ┆ 0.0      ┆ 0.0      │\n│ mean       ┆ null     ┆ null     │\n│ std        ┆ null     ┆ null     │\n│ min        ┆ null     ┆ null     │\n│ 25%        ┆ null     ┆ null     │\n│ 50%        ┆ null     ┆ null     │\n│ 75%        ┆ null     ┆ null     │\n│ max        ┆ null     ┆ null     │\n└────────────┴──────────┴──────────┘","text/html":"<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (9, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>it</th><th>en</th></tr><tr><td>str</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>480021.0</td><td>480021.0</td></tr><tr><td>&quot;null_count&quot;</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;mean&quot;</td><td>null</td><td>null</td></tr><tr><td>&quot;std&quot;</td><td>null</td><td>null</td></tr><tr><td>&quot;min&quot;</td><td>null</td><td>null</td></tr><tr><td>&quot;25%&quot;</td><td>null</td><td>null</td></tr><tr><td>&quot;50%&quot;</td><td>null</td><td>null</td></tr><tr><td>&quot;75%&quot;</td><td>null</td><td>null</td></tr><tr><td>&quot;max&quot;</td><td>null</td><td>null</td></tr></tbody></table></div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"seq2seq_input_data = loaded_data.sample(fraction = seq2seq_FRAC, seed = seq2seq_SEED)\n\nseq2seq_input_data.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T19:36:43.157779Z","iopub.execute_input":"2024-12-21T19:36:43.158142Z","iopub.status.idle":"2024-12-21T19:36:43.248789Z","shell.execute_reply.started":"2024-12-21T19:36:43.158109Z","shell.execute_reply":"2024-12-21T19:36:43.247775Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"shape: (9, 3)\n┌────────────┬──────────┬──────────┐\n│ statistic  ┆ it       ┆ en       │\n│ ---        ┆ ---      ┆ ---      │\n│ str        ┆ f64      ┆ f64      │\n╞════════════╪══════════╪══════════╡\n│ count      ┆ 192008.0 ┆ 192008.0 │\n│ null_count ┆ 0.0      ┆ 0.0      │\n│ mean       ┆ null     ┆ null     │\n│ std        ┆ null     ┆ null     │\n│ min        ┆ null     ┆ null     │\n│ 25%        ┆ null     ┆ null     │\n│ 50%        ┆ null     ┆ null     │\n│ 75%        ┆ null     ┆ null     │\n│ max        ┆ null     ┆ null     │\n└────────────┴──────────┴──────────┘","text/html":"<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (9, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>it</th><th>en</th></tr><tr><td>str</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>192008.0</td><td>192008.0</td></tr><tr><td>&quot;null_count&quot;</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;mean&quot;</td><td>null</td><td>null</td></tr><tr><td>&quot;std&quot;</td><td>null</td><td>null</td></tr><tr><td>&quot;min&quot;</td><td>null</td><td>null</td></tr><tr><td>&quot;25%&quot;</td><td>null</td><td>null</td></tr><tr><td>&quot;50%&quot;</td><td>null</td><td>null</td></tr><tr><td>&quot;75%&quot;</td><td>null</td><td>null</td></tr><tr><td>&quot;max&quot;</td><td>null</td><td>null</td></tr></tbody></table></div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"def build_vocab(tokens):\n    vocab = defaultdict(lambda: len(vocab))  # Assign unique indices\n    vocab[\"<pad>\"]  # Reserve 0 for padding\n    vocab[\"<unk>\"]\n    for token_list in tokens:\n        for token in token_list:\n            _ = vocab[token]\n    return dict(vocab)\n\ndef preprocess_data(df):\n    it_vocab = build_vocab(df[\"it\"])\n    en_vocab = build_vocab(df[\"en\"])\n    \n    it_indices = [\n        torch.tensor([it_vocab[token] for token in tokens], dtype=torch.long)\n        for tokens in df[\"it\"]\n    ]\n    en_indices = [\n        torch.tensor([en_vocab[token] for token in tokens], dtype=torch.long)\n        for tokens in df[\"en\"]\n    ]\n    return list(zip(en_indices, it_indices)), len(it_vocab), len(en_vocab), en_vocab, it_vocab","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T19:36:47.031549Z","iopub.execute_input":"2024-12-21T19:36:47.031845Z","iopub.status.idle":"2024-12-21T19:36:47.037702Z","shell.execute_reply.started":"2024-12-21T19:36:47.031820Z","shell.execute_reply":"2024-12-21T19:36:47.036747Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"seq2_seq_data_pairs, seq2seq_IT_VOCAB_SIZE, seq2seq_EN_VOCAB_SIZE, seq2seq_en_v, seq2seq_it_v = preprocess_data(seq2seq_input_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T19:36:57.702521Z","iopub.execute_input":"2024-12-21T19:36:57.702817Z","iopub.status.idle":"2024-12-21T19:37:05.336427Z","shell.execute_reply.started":"2024-12-21T19:36:57.702796Z","shell.execute_reply":"2024-12-21T19:37:05.335704Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"transformer_data_pairs, transformer_IT_VOCAB_SIZE, transformer_EN_VOCAB_SIZE, transformer_en_v, transformer_it_v = preprocess_data(transformer_input_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T19:37:21.047146Z","iopub.execute_input":"2024-12-21T19:37:21.047528Z","iopub.status.idle":"2024-12-21T19:37:39.835553Z","shell.execute_reply.started":"2024-12-21T19:37:21.047496Z","shell.execute_reply":"2024-12-21T19:37:39.834540Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n        super().__init__()\n        self.embedding = nn.Embedding(input_dim, emb_dim)\n        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout, batch_first=True)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, src):\n        embedded = self.dropout(self.embedding(src))\n        outputs, (hidden, cell) = self.rnn(embedded)\n        return hidden, cell\n\nclass Decoder(nn.Module):\n    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n        super().__init__()\n        self.embedding = nn.Embedding(output_dim, emb_dim)\n        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout, batch_first=True)\n        self.fc_out = nn.Linear(hid_dim, output_dim)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, trg, hidden, cell):\n        trg = trg.unsqueeze(1)\n        embedded = self.dropout(self.embedding(trg))\n        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n        prediction = self.fc_out(output.squeeze(1))\n        return prediction, hidden, cell","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T19:37:41.689651Z","iopub.execute_input":"2024-12-21T19:37:41.689988Z","iopub.status.idle":"2024-12-21T19:37:41.696790Z","shell.execute_reply.started":"2024-12-21T19:37:41.689960Z","shell.execute_reply":"2024-12-21T19:37:41.696041Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"class Seq2Seq(nn.Module):\n    def __init__(self, encoder, decoder, device):\n        super().__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n        self.device = device\n\n    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n        batch_size = src.size(0)\n        trg_len = trg.size(1)\n        trg_vocab_size = self.decoder.fc_out.out_features\n\n        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(self.device)\n\n        hidden, cell = self.encoder(src)\n\n        trg_input = trg[:, 0]\n        for t in range(1, trg_len):\n            output, hidden, cell = self.decoder(trg_input, hidden, cell)\n            outputs[:, t, :] = output\n            top1 = output.argmax(1)\n            trg_input = trg[:, t] if torch.rand(1).item() < teacher_forcing_ratio else top1\n\n        return outputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T19:37:43.840879Z","iopub.execute_input":"2024-12-21T19:37:43.841255Z","iopub.status.idle":"2024-12-21T19:37:43.847135Z","shell.execute_reply.started":"2024-12-21T19:37:43.841191Z","shell.execute_reply":"2024-12-21T19:37:43.846103Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"seq2seq_encoder = Encoder(seq2seq_EN_VOCAB_SIZE, seq2seq_EMB_DIM, seq2seq_HID_DIM, seq2seq_N_LAYERS, seq2seq_DROPOUT)\nseq2seq_decoder = Decoder(seq2seq_IT_VOCAB_SIZE, seq2seq_EMB_DIM, seq2seq_HID_DIM, seq2seq_N_LAYERS, seq2seq_DROPOUT)\nseq2seq_model = Seq2Seq(seq2seq_encoder, seq2seq_decoder, device).to(device)\n\nseq2seq_model.load_state_dict(torch.load(\"/kaggle/input/dec-enc-test/seq2seq_translation_model.pth\", weights_only=True))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T19:37:47.919766Z","iopub.execute_input":"2024-12-21T19:37:47.920080Z","iopub.status.idle":"2024-12-21T19:37:48.654418Z","shell.execute_reply.started":"2024-12-21T19:37:47.920057Z","shell.execute_reply":"2024-12-21T19:37:48.653248Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-64a8e94d10cd>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mseq2seq_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeq2Seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq2seq_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq2seq_decoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mseq2seq_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/kaggle/input/dec-enc-test/seq2seq_translation_model.pth\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2215\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   2216\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   2217\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Seq2Seq:\n\tsize mismatch for encoder.embedding.weight: copying a param with shape torch.Size([52520, 128]) from checkpoint, the shape in current model is torch.Size([52521, 128]).\n\tsize mismatch for decoder.embedding.weight: copying a param with shape torch.Size([79086, 128]) from checkpoint, the shape in current model is torch.Size([79087, 128]).\n\tsize mismatch for decoder.fc_out.weight: copying a param with shape torch.Size([79086, 258]) from checkpoint, the shape in current model is torch.Size([79087, 258]).\n\tsize mismatch for decoder.fc_out.bias: copying a param with shape torch.Size([79086]) from checkpoint, the shape in current model is torch.Size([79087])."],"ename":"RuntimeError","evalue":"Error(s) in loading state_dict for Seq2Seq:\n\tsize mismatch for encoder.embedding.weight: copying a param with shape torch.Size([52520, 128]) from checkpoint, the shape in current model is torch.Size([52521, 128]).\n\tsize mismatch for decoder.embedding.weight: copying a param with shape torch.Size([79086, 128]) from checkpoint, the shape in current model is torch.Size([79087, 128]).\n\tsize mismatch for decoder.fc_out.weight: copying a param with shape torch.Size([79086, 258]) from checkpoint, the shape in current model is torch.Size([79087, 258]).\n\tsize mismatch for decoder.fc_out.bias: copying a param with shape torch.Size([79086]) from checkpoint, the shape in current model is torch.Size([79087]).","output_type":"error"}],"execution_count":13},{"cell_type":"code","source":"class Transformer(nn.Module):\n    def __init__(self, src_vocab_size, trg_vocab_size, emb_dim, n_heads, ff_dim, n_layers, dropout):\n        super().__init__()\n        # Ensure src_vocab_size matches the vocabulary size from preprocessing\n        self.src_embedding = nn.Embedding(src_vocab_size, emb_dim)\n        # Ensure trg_vocab_size matches the vocabulary size from preprocessing\n        self.trg_embedding = nn.Embedding(trg_vocab_size, emb_dim)\n        # Check that the positional encoding length covers all sequence lengths\n        self.positional_encoding = self._get_positional_encoding(emb_dim)\n\n        self.transformer = nn.Transformer(\n            d_model=emb_dim,\n            nhead=n_heads,\n            num_encoder_layers=n_layers,\n            num_decoder_layers=n_layers,\n            dim_feedforward=ff_dim,\n            dropout=dropout,\n            batch_first=True\n        )\n        self.fc_out = nn.Linear(emb_dim, trg_vocab_size)\n\n    def forward(self, src, trg):\n        src_seq_len = src.size(1)  # Sequence length of source\n        src = self.src_embedding(src) + self.positional_encoding[:, :src_seq_len, :].to(src.device)\n        trg_seq_len = trg.size(1)  # Sequence length of target\n        trg = self.trg_embedding(trg) + self.positional_encoding[:, :trg_seq_len, :].to(trg.device)\n\n        src_mask = self._generate_square_subsequent_mask(src_seq_len).to(src.device)\n        trg_mask = self._generate_square_subsequent_mask(trg_seq_len).to(trg.device)\n        memory_mask = None\n\n        # Ensure src, trg, and masks are aligned\n        output = self.transformer(\n            src, trg, src_mask=src_mask, tgt_mask=trg_mask, memory_mask=memory_mask\n        )\n        output = self.fc_out(output)\n\n        return output\n\n    def _generate_square_subsequent_mask(self, sz):\n        return torch.triu(torch.full((sz, sz), float('-inf')), diagonal=1)\n\n    def _get_positional_encoding(self, emb_dim, max_len=5000):\n        pe = torch.zeros(1, max_len, emb_dim)\n        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, emb_dim, 2).float() * -(torch.log(torch.tensor(10000.0)) / emb_dim))\n        pe[0, :, 0::2] = torch.sin(position * div_term)\n        pe[0, :, 1::2] = torch.cos(position * div_term)\n        return pe","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"transformer_model = Transformer(transformer_EN_VOCAB_SIZE, transformer_IT_VOCAB_SIZE, transformer_EMB_DIM, transformer_N_HEADS, transformer_FF_DIM, transformer_N_LAYERS, transformer_DROPOUT).to(device)\n\ntransformer_model.load_state_dict(torch.load(\"/kaggle/input/transformer-translator/transformer_translation_model.pth\", weights_only=True))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"seq2seq_it_v_inv = {v: k for k, v in seq2seq_it_v.items()}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"transformer_it_v_inv = {v: k for k, v in transformer_it_v.items()}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def tokenize(sentence, vocab):\n    tokens = sentence.lower().split()  # Basic tokenization; adjust if needed\n    return torch.tensor([vocab.get(token, vocab[\"<unk>\"]) for token in tokens], dtype=torch.long)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def seq2seq_translate(sentence, model, en_vocab, it_vocab_inv, device=\"cuda\"):\n    model.eval()\n    model.to(device)\n\n    input_tensor = tokenize(sentence, en_vocab).unsqueeze(0).to(device)\n    hidden_state, cell_state = model.encoder(input_tensor)\n    \n    decoded_tokens = []\n    decoder_input = torch.tensor([it_vocab[\"<bos>\"]], dtype=torch.long, device=device)\n\n    for _ in range(50):  # Limit translation to 50 tokens\n        output, (hidden_state, cell_state) = model.decoder(\n            decoder_input.unsqueeze(0), (hidden_state, cell_state)\n        )\n        next_token = output.argmax(2).item()\n        if next_token == it_vocab[\"<eos>\"]:\n            break\n        decoded_tokens.append(it_vocab_inv[next_token])\n        decoder_input = torch.tensor([next_token], dtype=torch.long, device=device)\n\n    return \" \".join(decoded_tokens)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def transformer_translate(sentence, model, en_vocab, it_vocab_inv, device=\"cuda\"):\n    model.eval()\n    model.to(device)\n\n    input_tensor = tokenize(sentence, en_vocab).unsqueeze(0).to(device)\n    src_mask = model.generate_square_subsequent_mask(input_tensor.size(1)).to(device)\n\n    memory = model.encoder(input_tensor, src_key_padding_mask=None)\n    decoded_tokens = []\n    decoder_input = torch.tensor([it_vocab[\"<bos>\"]], dtype=torch.long, device=device)\n\n    for _ in range(50):\n        tgt_mask = model.generate_square_subsequent_mask(len(decoded_tokens) + 1).to(device)\n        output = model.decoder(\n            decoder_input.unsqueeze(0), memory, tgt_mask=tgt_mask\n        )\n        next_token = output.argmax(2).item()\n        if next_token == it_vocab[\"<eos>\"]:\n            break\n        decoded_tokens.append(it_vocab_inv[next_token])\n        decoder_input = torch.tensor([next_token], dtype=torch.long, device=device)\n\n    return \" \".join(decoded_tokens)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def translate(sentence, model_type=\"seq2seq\", device=\"cuda\"):\n    if model_type == \"seq2seq\":\n        return seq2seq_translate(sentence, seq2seq_model, seq2seq_en_v, seq2seq_it_v_inv, device)\n    elif model_type == \"transformer\":\n        return transformer_translate(sentence, transformer_model, transformer_en_v, transformer_it_v_inv, device)\n    else:\n        raise ValueError(\"Invalid model_type. Choose 'seq2seq' or 'transformer'.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sentence = \"How are you today? good day I hope\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"seq2seq_translation = translate(sentence)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Sentence Translation (Using Seq2Seq Model): \", seq2seq_translation)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"transformer_translation = translate(sentence, model_type = \"transformer\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Sentence Translation (Using Transformer Model): \", transformer_translation)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
